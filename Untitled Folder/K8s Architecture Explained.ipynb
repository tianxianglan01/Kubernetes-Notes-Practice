{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c570f580",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "- Two types of nodes in K8s: One is Master. The other is slave.\n",
    "- Go through basic concepts of how K8s does what it does \n",
    "- and how cluster is self managed, and self healing, and automated\n",
    "- and how you as an operator of k8s cluster should end up having much less manual effort\n",
    "\n",
    "Slave/Worker Nodes: container runtime, kubelet, kube proxy\n",
    "\n",
    "Master Nodes: API server, scheduler, Controller Manager, etcd\n",
    "\n",
    "Our Example: one node with 2 application pods running on it. \n",
    "\n",
    "One components of K8s architecture is are its worker servers or nodes. Each node will have multiple application pods running on it. It does it by using 3 processes that must be installed on every node to scheudle and manage the pods. \n",
    "\n",
    "Nodes are the cluster servers that actually do the work. Hence 'worker nodes'.\n",
    "\n",
    "1) First process that needs to run every node is the container runtime. Example: docker.\n",
    "\n",
    "Cause application pods have containers running inside, an application run time needs to be installed on every node. The process that actually schedules those pods and the container that are underneath is called kubelet. \n",
    "\n",
    "A container runtime is software that executes containers and manages container images on a node.\n",
    "\n",
    "2) Kubelet is a process of k8s itself, like container runtime, that has interface with both container runtime and the machine (the node itself). At the end of the day, kubelet is responsible for taking that configuration and running a pod or starting a pod with a container inside and assigning resources from that node to that container (cpu, ram, storage resources).\n",
    "\n",
    "Usually K8s clusters are made of multiple nodes which also must have container runtimes and kubulet services installed. We can have hudnreds of worker nodes which will run other pods and containers and replicas of existing pods like my app and database pods. \n",
    "\n",
    "The way nodes communicate with one another is called *Services* which is a load balancer which catches requests directed to the pod of the app like the db for example and forwards it to the respective pod. \n",
    "\n",
    "3) The third process is responsible for forwarding requests from services to pods is called kube proxy which also must be installed on every node. KubeProxy has intelligent forwarding logic inside that makes sure the communication works in a performant way with low overhead.\n",
    "\n",
    "Example: if an app, my app replica, is making a request to a database, instead of service just randomly forwarding the request to any replica, it will actually forward it to the replica that is running on the same node as the pod that intiated the request. Thus this avoids the network overhead of sending the request to another machine.\n",
    "\n",
    "#### Summary\n",
    "2 K8s processes\n",
    "1) Kubelet\n",
    "2) Kube Proxy\n",
    "\n",
    "must be installed on every k8s worker nodes along with an independent \n",
    "\n",
    "3) container runtime\n",
    "\n",
    "in order for K8s to function properly. \n",
    "\n",
    "Now the question is how do you interact with this cluster?\n",
    "\n",
    "- Do you decide on which node or new app pod or database pod should be scheudled?\n",
    "- or if the replica pod dies, what process monitors it and then reschedules it or restarts it again? \n",
    "- or add another server, how does it join the cluster to become another node and gets pods and other components created on it? \n",
    "\n",
    "#### The answer to these three questions is: \n",
    "Managing processes are done by Master Nodes. \n",
    "\n",
    "Master processes\n",
    "\n",
    "Master Servers (Master Nodes) have different processes running inside and these are four processes that run on every master node that control cluster state and worker nodes.\n",
    "\n",
    "1) API server: when you as a user want to deploy a new app in a k8s cluster, you interact with the api server using client like a UI K8s dashboard, CLI tool like Kubelet or a k8s api\n",
    "- An Api Server is like a cluster gateway which gets the intial request of the any updates into the cluster or even the queries from the cluster. It also acts as a gatekeeper for authentication to make sure only authenticated and authorized requests get through to the cluster.\n",
    "- this means when you want to schedule new pods, deploy new apps, create new service or any other components, you have to talk to the api server on the master node and the api server then validates requests and if everything is fine, then it will forward your request to other processes in order to schedule the pod or create this component you requested\n",
    "- also if you want to the query the status of your deployemnt or cluster heatlh, etc, you make a request to the api server and it gives you the response.\n",
    "- which is good for security cause you have only one entry point into the cluster\n",
    "\n",
    "2) another master process is a scheduler \n",
    "- if you send an api server a request to schedule a new pod, the api server after it validates your request and will hand it over to the scheduler in order to start the application pod on one of the worker nodes.\n",
    "- and instead of randomly assining to any node, the scheduler has an intelligent way of deciding which specific worker node the next pod will be scheduled or next component will be scheduled.\n",
    "- first it will look at request and see how many resources the app you want to schedule will need: how much cpu, how much ram, and then it's going to look at and go through the worker nodes and see available resources on each one of them.\n",
    "- if it sees one load is the least busy or has the most resources available, it will schedule the new pod on that node. \n",
    "- note that scheduler decides on which node a new pod will be scheduled.\n",
    "- the process that actually does the scheduling, that starts that pod with a container, is Kubelet which gets a request from the scheduler and then Kubelet executes that request on that node the scheduler decides on.\n",
    "\n",
    "3) Controller maanger\n",
    "- so when pods die on any node, there must be a way to detect when nodes died and reschedule those pods as soon as possible\n",
    "- so the controller manager detects state changes like crashing of pods\n",
    "\n",
    "So when a pod dies, the controller manager detects the death and tries to recover the cluster state ASAP and for that it makes a request for the scheduler to reschedule those dead pods. \n",
    "\n",
    "And the same cycle happens here where the scheduler decides based on the resource calculation which worker nodes should restart those pods again and makes requests to the corresponding kublet on those worker nodes to restart the pods.\n",
    "\n",
    "4) etcd\n",
    "- a key value store of a cluster state.\n",
    "- can think of it as a cluster brain: which means every change in the cluster (when a new pod gets scheduled or when a pod dies) all these changes get saved or updated into etcd key value store\n",
    "- etcd store is a cluster brain is because all of this mechanism with scheduler controller manager etc works because of its data. \n",
    "- ie how a scheduler knows what resources are available on each worker node or how does controller managaer know a cluster state change in some way (pod death or kubelet restarted new pod on request of shceduler). Or when you make a query request to an api server about the cluster health or your app deployment state - where does api server get all this state info from?\n",
    "- all of this info is stored in etcd\n",
    "- what is not stored in etcd key value store is the actual application data ie a database ap running in cluster, the data would be stored somwehre else and not in etcd. \n",
    "- this is cluster state info which is used for master processes to communicate with work processes and vice versa\n",
    "\n",
    "Master Processes are crucial for cluster operations: especially etcd store which contains some data must be reliabily stored and replicated. IN practice K8s clusters are made up of multiple masters where each master node runs its master processes. Where the api server is load balanced and etcd store forms a distributed storage across all the master nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b2550",
   "metadata": {},
   "source": [
    "#### Example Cluster Setup\n",
    "\n",
    "In this example of a small cluster, you would have 2 master nodes, and three worker nodes. \n",
    "\n",
    "Denote the hardware resources of master and node servers differ. The master processes are more important but they have less load of work so they need fewer resources like CPU, Ram and Storage. On the other hand worker nodes do the actual job of running those pods with containers inside therefore they need resources. \n",
    "\n",
    "As your app complexity and demand of resources increases, you may actually add more master and node servers to your cluster and thus forming a more powerful and robust cluster to meet your applicaiton resource requirements. \n",
    "\n",
    "IN an existing K8s cluster, you can add new master or node servers pretty easily.\n",
    "1) to add a master server, get a new bare server\n",
    "2) install all the master/worker node processes\n",
    "3) add it to the cluster\n",
    "\n",
    "Same way as above to add 2 worker nodes\n",
    "1) get bare servers\n",
    "2) worker node processes (container runtime, kubelet, and kube proxy)\n",
    "3) add to K8s cluster.\n",
    "\n",
    "This way you can infinitely increase power and resources of K8s cluster as your app complexity and resource demand increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcd55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
